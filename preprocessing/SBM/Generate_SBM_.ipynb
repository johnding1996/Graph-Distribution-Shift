{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for generating and saving SBM PATTERN graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate SBM PATTERN graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 0., 0., 1., 0., 0., 2., 0., 2., 1., 0., 1., 0., 2., 1., 0., 0., 2.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 2., 1., 1., 1., 1., 1., 2.,\n",
      "        2., 1., 0., 0., 0., 0., 0., 2., 0., 2., 2., 1., 0., 1., 0., 2., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 2., 0., 2., 1., 1., 1., 0., 2., 1., 0., 0.,\n",
      "        1., 1., 0., 2., 2., 1., 2., 0., 2., 1., 0., 0., 0., 2., 1., 1., 0., 0.,\n",
      "        2., 2., 1., 1., 1., 1., 2., 0., 1., 1., 1., 0., 2., 2., 1., 2., 0., 1.,\n",
      "        0., 1., 2., 0., 0., 2., 2., 2., 2., 1., 1., 0., 0., 2., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 2., 2., 0., 2., 2.])\n",
      "tensor(8)\n",
      "tensor([[  0,   0,   0,  ..., 137, 137, 137],\n",
      "        [  1,   4,   7,  ..., 129, 130, 136]])\n",
      "torch.Size([138])\n",
      "torch.Size([])\n",
      "torch.Size([2, 7892])\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "def schuffle(W,c):\n",
    "    # relabel the vertices at random\n",
    "    idx=np.random.permutation( W.shape[0] )\n",
    "    #idx2=np.argsort(idx) # for index ordering wrt classes\n",
    "    W_new=W[idx,:]\n",
    "    W_new=W_new[:,idx]\n",
    "    c_new=c[idx]\n",
    "    return W_new , c_new , idx \n",
    "\n",
    "\n",
    "def block_model(c,p,q):\n",
    "    n=len(c)\n",
    "    W=np.zeros((n,n), dtype=np.int64)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            if c[i]==c[j]:\n",
    "                prob=p\n",
    "            else:\n",
    "                prob=q\n",
    "            if np.random.binomial(1,prob)==1:\n",
    "                W[i,j]=1\n",
    "                W[j,i]=1     \n",
    "    return W\n",
    "\n",
    "\n",
    "def unbalanced_block_model(nb_of_clust, clust_size_min, clust_size_max, p, q):  \n",
    "    c = []\n",
    "    for r in range(nb_of_clust):\n",
    "        if clust_size_max==clust_size_min:\n",
    "            clust_size_r = clust_size_max\n",
    "        else:\n",
    "            clust_size_r = np.random.randint(clust_size_min,clust_size_max,size=1)[0]\n",
    "        val_r = np.repeat(r,clust_size_r,axis=0)\n",
    "        c.append(val_r)\n",
    "    c = np.concatenate(c)  \n",
    "    W = block_model(c,p,q)  \n",
    "    return W,c\n",
    "\n",
    "\n",
    "def random_pattern(n,p):\n",
    "    W=np.zeros((n,n), dtype=np.int64)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            if np.random.binomial(1,p)==1:\n",
    "                W[i,j]=1\n",
    "                W[j,i]=1     \n",
    "    return W    \n",
    "\n",
    "\n",
    "    \n",
    "def add_pattern(W0,W,c,nb_of_clust,q):\n",
    "    n=W.shape[0]\n",
    "    n0=W0.shape[0]\n",
    "    V=(np.random.rand(n0,n) < q).astype(float)\n",
    "    W_up=np.concatenate(  ( W , V.T ) , axis=1 )\n",
    "    W_low=np.concatenate( ( V , W0  ) , axis=1 )\n",
    "    W_new=np.concatenate( (W_up,W_low)  , axis=0)\n",
    "    c0=np.full(n0,nb_of_clust)\n",
    "    c_new=np.concatenate( (c, c0),axis=0)\n",
    "    return W_new,c_new\n",
    "\n",
    "def adj_to_edge_list(W):\n",
    "    e=int(np.sum(W))\n",
    "    edge_index = np.zeros((2,e), dtype=np.int64)\n",
    "    n=W.shape[0]\n",
    "    counter = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if W[i,j]==1:\n",
    "                edge_index[0, counter] = i\n",
    "                edge_index[1, counter] = j\n",
    "                counter += 1\n",
    "    assert counter == e\n",
    "    return edge_index\n",
    "    \n",
    "\n",
    "\n",
    "class generate_SBM_graph():\n",
    "\n",
    "    def __init__(self, SBM_parameters): \n",
    "\n",
    "        # parameters\n",
    "        nb_of_clust = SBM_parameters['nb_clusters']\n",
    "        clust_size_min = SBM_parameters['size_min']\n",
    "        clust_size_max = SBM_parameters['size_max']\n",
    "        p = SBM_parameters['p']\n",
    "        q = SBM_parameters['q']\n",
    "        p_pattern = SBM_parameters['p_pattern']\n",
    "        q_pattern = SBM_parameters['q_pattern']\n",
    "        vocab_size = SBM_parameters['vocab_size']\n",
    "        W0 = SBM_parameters['W0']\n",
    "        u0 = SBM_parameters['u0']\n",
    "\n",
    "        # block model\n",
    "        W, c = unbalanced_block_model(nb_of_clust, clust_size_min, clust_size_max, p, q)\n",
    "        \n",
    "        # signal on block model\n",
    "        u = np.random.randint(vocab_size, size=W.shape[0])\n",
    "        \n",
    "        # add the subgraph to be detected\n",
    "        W, c = add_pattern(W0,W,c,nb_of_clust,q_pattern)\n",
    "        u = np.concatenate((u,u0),axis=0)\n",
    "        \n",
    "        # shuffle\n",
    "        W, c, idx = schuffle(W,c)\n",
    "        u = u[idx]\n",
    "    \n",
    "        # target\n",
    "        # target = (c==nb_of_clust).astype(float)\n",
    "        \n",
    "        # convert to pytorch\n",
    "        edge_index = adj_to_edge_list(W)\n",
    "        edge_index = torch.from_numpy(edge_index)\n",
    "        edge_index = edge_index.to(torch.int64)\n",
    "        #idx = torch.from_numpy(idx) \n",
    "        #idx = idx.to(torch.int16)\n",
    "        u = torch.from_numpy(u) \n",
    "        u = u.to(torch.float32)                      \n",
    "        #target = torch.from_numpy(target)\n",
    "        #target = target.to(torch.int16)\n",
    "        \n",
    "        # attributes\n",
    "        #self.nb_nodes = W.size(0)\n",
    "        self.edge_index = edge_index\n",
    "        #self.rand_idx = idx\n",
    "        self.x = u\n",
    "        #self.node_label = target\n",
    "        self.y = torch.tensor(W.shape[0] % 10)\n",
    "        \n",
    "        \n",
    "# configuration\n",
    "SBM_parameters = {}\n",
    "SBM_parameters['nb_clusters'] = 5\n",
    "SBM_parameters['size_min'] = 5\n",
    "SBM_parameters['size_max'] = 35\n",
    "SBM_parameters['p'] = 0.5\n",
    "SBM_parameters['q'] = 0.35\n",
    "SBM_parameters['p_pattern'] = 0.5\n",
    "SBM_parameters['q_pattern'] = 0.5\n",
    "SBM_parameters['vocab_size'] = 3\n",
    "SBM_parameters['size_subgraph'] = 20\n",
    "SBM_parameters['W0'] = random_pattern(SBM_parameters['size_subgraph'],SBM_parameters['p_pattern'])\n",
    "SBM_parameters['u0'] = np.random.randint(SBM_parameters['vocab_size'],size=SBM_parameters['size_subgraph'])\n",
    "        \n",
    "data = generate_SBM_graph(SBM_parameters)\n",
    "\n",
    "print(data.x)\n",
    "print(data.y)\n",
    "print(data.edge_index)\n",
    "print(data.x.shape)\n",
    "print(data.y.shape)\n",
    "print(data.edge_index.shape)\n",
    "print(data.x.dtype)\n",
    "print(data.y.dtype)\n",
    "print(data.edge_index.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb_clusters': 5, 'size_min': 5, 'size_max': 35, 'p': 0.5, 'q': 0.35, 'p_pattern': 0.5, 'q_pattern': 0.5, 'vocab_size': 3, 'size_subgraph_min': 15, 'size_subgraph_max': 25}\n",
      "pattern: 0\n",
      "pattern: 1\n",
      "pattern: 2\n",
      "pattern: 3\n",
      "pattern: 4\n",
      "pattern: 5\n",
      "pattern: 6\n",
      "pattern: 7\n",
      "pattern: 8\n",
      "pattern: 9\n",
      "pattern: 10\n",
      "pattern: 11\n",
      "pattern: 12\n",
      "pattern: 13\n",
      "pattern: 14\n",
      "pattern: 15\n",
      "pattern: 16\n",
      "pattern: 17\n",
      "pattern: 18\n",
      "pattern: 19\n",
      "pattern: 20\n",
      "pattern: 21\n",
      "pattern: 22\n",
      "pattern: 23\n",
      "pattern: 24\n",
      "pattern: 25\n",
      "pattern: 26\n",
      "pattern: 27\n",
      "pattern: 28\n",
      "pattern: 29\n",
      "pattern: 30\n",
      "pattern: 31\n",
      "pattern: 32\n",
      "pattern: 33\n",
      "pattern: 34\n",
      "pattern: 35\n",
      "pattern: 36\n",
      "pattern: 37\n",
      "pattern: 38\n",
      "pattern: 39\n",
      "pattern: 40\n",
      "pattern: 41\n",
      "pattern: 42\n",
      "pattern: 43\n",
      "pattern: 44\n",
      "pattern: 45\n",
      "pattern: 46\n",
      "pattern: 47\n",
      "pattern: 48\n",
      "pattern: 49\n",
      "5000\n",
      "Time (sec): 95.16405367851257\n"
     ]
    }
   ],
   "source": [
    "# Generate and save SBM graphs\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# configuration for 100 patterns 100/20 \n",
    "nb_pattern_instances = 50 # nb of patterns\n",
    "nb_graphs_per_pattern_instance = 100 # train per pattern\n",
    "\n",
    "# # debug\n",
    "# nb_pattern_instances = 10 # nb of patterns\n",
    "# nb_train_graphs_per_pattern_instance = 10 # train per pattern\n",
    "# nb_test_graphs_per_pattern_instance = 2 # test, val per pattern\n",
    "# # debug\n",
    "\n",
    "SBM_parameters = {}\n",
    "SBM_parameters['nb_clusters'] = 5 \n",
    "SBM_parameters['size_min'] = 5 \n",
    "SBM_parameters['size_max'] = 35 \n",
    "#SBM_parameters['p'] = 0.5 # v1\n",
    "#SBM_parameters['q'] = 0.2 # v1\n",
    "#SBM_parameters['p'] = 0.5 # v2\n",
    "#SBM_parameters['q'] = 0.5 # v2\n",
    "#SBM_parameters['p'] = 0.5; SBM_parameters['q'] = 0.25 # v3\n",
    "SBM_parameters['p'] = 0.5; SBM_parameters['q'] = 0.35 # v4\n",
    "SBM_parameters['p_pattern'] = 0.5 \n",
    "SBM_parameters['q_pattern'] = 0.5  \n",
    "SBM_parameters['vocab_size'] = 3 \n",
    "#SBM_parameters['size_subgraph'] = 20 # v1\n",
    "SBM_parameters['size_subgraph_min'] = 15 # v2\n",
    "SBM_parameters['size_subgraph_max'] = 25 # v2\n",
    "print(SBM_parameters)\n",
    "    \n",
    "\n",
    "dataset = []\n",
    "group_index = []\n",
    "for idx in range(nb_pattern_instances):\n",
    "    \n",
    "    print('pattern:', idx)\n",
    "    \n",
    "    #SBM_parameters['W0'] = random_pattern(SBM_parameters['size_subgraph'],SBM_parameters['p']) # v1\n",
    "    #SBM_parameters['u0'] = np.random.randint(SBM_parameters['vocab_size'],size=SBM_parameters['size_subgraph']) # v1\n",
    "    size_subgraph = np.random.randint(SBM_parameters['size_subgraph_min'], SBM_parameters['size_subgraph_max'],size=1)[0] # v2\n",
    "    SBM_parameters['size_subgraph'] = size_subgraph\n",
    "    SBM_parameters['W0'] = random_pattern(size_subgraph,SBM_parameters['p']) # v2\n",
    "    SBM_parameters['u0'] = np.random.randint(SBM_parameters['vocab_size'],size=size_subgraph) # v2\n",
    "    \n",
    "    for _ in range(nb_graphs_per_pattern_instance):\n",
    "        data = generate_SBM_graph(SBM_parameters)\n",
    "        graph = {}\n",
    "        graph['x'] = data.x.view(data.x.shape[0], 1) \n",
    "        graph['y'] = data.y.long()\n",
    "        graph['edge_index'] = data.edge_index\n",
    "        dataset.append(graph)\n",
    "        group_index.append(idx)\n",
    "\n",
    "group_index = np.array(group_index, dtype=np.int64)\n",
    "print(len(dataset))\n",
    "\n",
    "torch.save(dataset, 'SBM1.pt')\n",
    "np.save('SBM1_group.npy', group_index)\n",
    "    \n",
    "print('Time (sec):',time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
