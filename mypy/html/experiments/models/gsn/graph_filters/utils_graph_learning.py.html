<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" type="text/css" href="../../../../../mypy-html.css">
</head>
<body>
<h2>experiments.models.gsn.graph_filters.utils_graph_learning</h2>
<table>
<caption>experiments/models/gsn/graph_filters/utils_graph_learning.py</caption>
<tbody><tr>
<td class="table-lines"><pre><span id="L1" class="lineno"><a class="lineno" href="#L1">1</a></span>
<span id="L2" class="lineno"><a class="lineno" href="#L2">2</a></span>
<span id="L3" class="lineno"><a class="lineno" href="#L3">3</a></span>
<span id="L4" class="lineno"><a class="lineno" href="#L4">4</a></span>
<span id="L5" class="lineno"><a class="lineno" href="#L5">5</a></span>
<span id="L6" class="lineno"><a class="lineno" href="#L6">6</a></span>
<span id="L7" class="lineno"><a class="lineno" href="#L7">7</a></span>
<span id="L8" class="lineno"><a class="lineno" href="#L8">8</a></span>
<span id="L9" class="lineno"><a class="lineno" href="#L9">9</a></span>
<span id="L10" class="lineno"><a class="lineno" href="#L10">10</a></span>
<span id="L11" class="lineno"><a class="lineno" href="#L11">11</a></span>
<span id="L12" class="lineno"><a class="lineno" href="#L12">12</a></span>
<span id="L13" class="lineno"><a class="lineno" href="#L13">13</a></span>
<span id="L14" class="lineno"><a class="lineno" href="#L14">14</a></span>
<span id="L15" class="lineno"><a class="lineno" href="#L15">15</a></span>
<span id="L16" class="lineno"><a class="lineno" href="#L16">16</a></span>
<span id="L17" class="lineno"><a class="lineno" href="#L17">17</a></span>
<span id="L18" class="lineno"><a class="lineno" href="#L18">18</a></span>
<span id="L19" class="lineno"><a class="lineno" href="#L19">19</a></span>
<span id="L20" class="lineno"><a class="lineno" href="#L20">20</a></span>
<span id="L21" class="lineno"><a class="lineno" href="#L21">21</a></span>
<span id="L22" class="lineno"><a class="lineno" href="#L22">22</a></span>
<span id="L23" class="lineno"><a class="lineno" href="#L23">23</a></span>
<span id="L24" class="lineno"><a class="lineno" href="#L24">24</a></span>
<span id="L25" class="lineno"><a class="lineno" href="#L25">25</a></span>
<span id="L26" class="lineno"><a class="lineno" href="#L26">26</a></span>
<span id="L27" class="lineno"><a class="lineno" href="#L27">27</a></span>
<span id="L28" class="lineno"><a class="lineno" href="#L28">28</a></span>
<span id="L29" class="lineno"><a class="lineno" href="#L29">29</a></span>
<span id="L30" class="lineno"><a class="lineno" href="#L30">30</a></span>
<span id="L31" class="lineno"><a class="lineno" href="#L31">31</a></span>
<span id="L32" class="lineno"><a class="lineno" href="#L32">32</a></span>
<span id="L33" class="lineno"><a class="lineno" href="#L33">33</a></span>
<span id="L34" class="lineno"><a class="lineno" href="#L34">34</a></span>
<span id="L35" class="lineno"><a class="lineno" href="#L35">35</a></span>
<span id="L36" class="lineno"><a class="lineno" href="#L36">36</a></span>
<span id="L37" class="lineno"><a class="lineno" href="#L37">37</a></span>
<span id="L38" class="lineno"><a class="lineno" href="#L38">38</a></span>
<span id="L39" class="lineno"><a class="lineno" href="#L39">39</a></span>
<span id="L40" class="lineno"><a class="lineno" href="#L40">40</a></span>
<span id="L41" class="lineno"><a class="lineno" href="#L41">41</a></span>
<span id="L42" class="lineno"><a class="lineno" href="#L42">42</a></span>
<span id="L43" class="lineno"><a class="lineno" href="#L43">43</a></span>
<span id="L44" class="lineno"><a class="lineno" href="#L44">44</a></span>
<span id="L45" class="lineno"><a class="lineno" href="#L45">45</a></span>
<span id="L46" class="lineno"><a class="lineno" href="#L46">46</a></span>
<span id="L47" class="lineno"><a class="lineno" href="#L47">47</a></span>
<span id="L48" class="lineno"><a class="lineno" href="#L48">48</a></span>
<span id="L49" class="lineno"><a class="lineno" href="#L49">49</a></span>
<span id="L50" class="lineno"><a class="lineno" href="#L50">50</a></span>
<span id="L51" class="lineno"><a class="lineno" href="#L51">51</a></span>
<span id="L52" class="lineno"><a class="lineno" href="#L52">52</a></span>
<span id="L53" class="lineno"><a class="lineno" href="#L53">53</a></span>
<span id="L54" class="lineno"><a class="lineno" href="#L54">54</a></span>
<span id="L55" class="lineno"><a class="lineno" href="#L55">55</a></span>
<span id="L56" class="lineno"><a class="lineno" href="#L56">56</a></span>
<span id="L57" class="lineno"><a class="lineno" href="#L57">57</a></span>
<span id="L58" class="lineno"><a class="lineno" href="#L58">58</a></span>
<span id="L59" class="lineno"><a class="lineno" href="#L59">59</a></span>
<span id="L60" class="lineno"><a class="lineno" href="#L60">60</a></span>
<span id="L61" class="lineno"><a class="lineno" href="#L61">61</a></span>
<span id="L62" class="lineno"><a class="lineno" href="#L62">62</a></span>
<span id="L63" class="lineno"><a class="lineno" href="#L63">63</a></span>
<span id="L64" class="lineno"><a class="lineno" href="#L64">64</a></span>
<span id="L65" class="lineno"><a class="lineno" href="#L65">65</a></span>
<span id="L66" class="lineno"><a class="lineno" href="#L66">66</a></span>
<span id="L67" class="lineno"><a class="lineno" href="#L67">67</a></span>
<span id="L68" class="lineno"><a class="lineno" href="#L68">68</a></span>
<span id="L69" class="lineno"><a class="lineno" href="#L69">69</a></span>
<span id="L70" class="lineno"><a class="lineno" href="#L70">70</a></span>
<span id="L71" class="lineno"><a class="lineno" href="#L71">71</a></span>
<span id="L72" class="lineno"><a class="lineno" href="#L72">72</a></span>
<span id="L73" class="lineno"><a class="lineno" href="#L73">73</a></span>
<span id="L74" class="lineno"><a class="lineno" href="#L74">74</a></span>
<span id="L75" class="lineno"><a class="lineno" href="#L75">75</a></span>
<span id="L76" class="lineno"><a class="lineno" href="#L76">76</a></span>
<span id="L77" class="lineno"><a class="lineno" href="#L77">77</a></span>
<span id="L78" class="lineno"><a class="lineno" href="#L78">78</a></span>
<span id="L79" class="lineno"><a class="lineno" href="#L79">79</a></span>
<span id="L80" class="lineno"><a class="lineno" href="#L80">80</a></span>
<span id="L81" class="lineno"><a class="lineno" href="#L81">81</a></span>
<span id="L82" class="lineno"><a class="lineno" href="#L82">82</a></span>
<span id="L83" class="lineno"><a class="lineno" href="#L83">83</a></span>
<span id="L84" class="lineno"><a class="lineno" href="#L84">84</a></span>
<span id="L85" class="lineno"><a class="lineno" href="#L85">85</a></span>
<span id="L86" class="lineno"><a class="lineno" href="#L86">86</a></span>
<span id="L87" class="lineno"><a class="lineno" href="#L87">87</a></span>
<span id="L88" class="lineno"><a class="lineno" href="#L88">88</a></span>
<span id="L89" class="lineno"><a class="lineno" href="#L89">89</a></span>
<span id="L90" class="lineno"><a class="lineno" href="#L90">90</a></span>
<span id="L91" class="lineno"><a class="lineno" href="#L91">91</a></span>
<span id="L92" class="lineno"><a class="lineno" href="#L92">92</a></span>
<span id="L93" class="lineno"><a class="lineno" href="#L93">93</a></span>
<span id="L94" class="lineno"><a class="lineno" href="#L94">94</a></span>
<span id="L95" class="lineno"><a class="lineno" href="#L95">95</a></span>
<span id="L96" class="lineno"><a class="lineno" href="#L96">96</a></span>
<span id="L97" class="lineno"><a class="lineno" href="#L97">97</a></span>
<span id="L98" class="lineno"><a class="lineno" href="#L98">98</a></span>
<span id="L99" class="lineno"><a class="lineno" href="#L99">99</a></span>
<span id="L100" class="lineno"><a class="lineno" href="#L100">100</a></span>
<span id="L101" class="lineno"><a class="lineno" href="#L101">101</a></span>
<span id="L102" class="lineno"><a class="lineno" href="#L102">102</a></span>
<span id="L103" class="lineno"><a class="lineno" href="#L103">103</a></span>
<span id="L104" class="lineno"><a class="lineno" href="#L104">104</a></span>
<span id="L105" class="lineno"><a class="lineno" href="#L105">105</a></span>
<span id="L106" class="lineno"><a class="lineno" href="#L106">106</a></span>
<span id="L107" class="lineno"><a class="lineno" href="#L107">107</a></span>
<span id="L108" class="lineno"><a class="lineno" href="#L108">108</a></span>
<span id="L109" class="lineno"><a class="lineno" href="#L109">109</a></span>
<span id="L110" class="lineno"><a class="lineno" href="#L110">110</a></span>
<span id="L111" class="lineno"><a class="lineno" href="#L111">111</a></span>
<span id="L112" class="lineno"><a class="lineno" href="#L112">112</a></span>
<span id="L113" class="lineno"><a class="lineno" href="#L113">113</a></span>
<span id="L114" class="lineno"><a class="lineno" href="#L114">114</a></span>
<span id="L115" class="lineno"><a class="lineno" href="#L115">115</a></span>
<span id="L116" class="lineno"><a class="lineno" href="#L116">116</a></span>
<span id="L117" class="lineno"><a class="lineno" href="#L117">117</a></span>
<span id="L118" class="lineno"><a class="lineno" href="#L118">118</a></span>
<span id="L119" class="lineno"><a class="lineno" href="#L119">119</a></span>
<span id="L120" class="lineno"><a class="lineno" href="#L120">120</a></span>
<span id="L121" class="lineno"><a class="lineno" href="#L121">121</a></span>
<span id="L122" class="lineno"><a class="lineno" href="#L122">122</a></span>
<span id="L123" class="lineno"><a class="lineno" href="#L123">123</a></span>
<span id="L124" class="lineno"><a class="lineno" href="#L124">124</a></span>
<span id="L125" class="lineno"><a class="lineno" href="#L125">125</a></span>
<span id="L126" class="lineno"><a class="lineno" href="#L126">126</a></span>
<span id="L127" class="lineno"><a class="lineno" href="#L127">127</a></span>
<span id="L128" class="lineno"><a class="lineno" href="#L128">128</a></span>
<span id="L129" class="lineno"><a class="lineno" href="#L129">129</a></span>
<span id="L130" class="lineno"><a class="lineno" href="#L130">130</a></span>
<span id="L131" class="lineno"><a class="lineno" href="#L131">131</a></span>
<span id="L132" class="lineno"><a class="lineno" href="#L132">132</a></span>
<span id="L133" class="lineno"><a class="lineno" href="#L133">133</a></span>
<span id="L134" class="lineno"><a class="lineno" href="#L134">134</a></span>
<span id="L135" class="lineno"><a class="lineno" href="#L135">135</a></span>
<span id="L136" class="lineno"><a class="lineno" href="#L136">136</a></span>
<span id="L137" class="lineno"><a class="lineno" href="#L137">137</a></span>
<span id="L138" class="lineno"><a class="lineno" href="#L138">138</a></span>
<span id="L139" class="lineno"><a class="lineno" href="#L139">139</a></span>
<span id="L140" class="lineno"><a class="lineno" href="#L140">140</a></span>
<span id="L141" class="lineno"><a class="lineno" href="#L141">141</a></span>
<span id="L142" class="lineno"><a class="lineno" href="#L142">142</a></span>
<span id="L143" class="lineno"><a class="lineno" href="#L143">143</a></span>
<span id="L144" class="lineno"><a class="lineno" href="#L144">144</a></span>
<span id="L145" class="lineno"><a class="lineno" href="#L145">145</a></span>
<span id="L146" class="lineno"><a class="lineno" href="#L146">146</a></span>
<span id="L147" class="lineno"><a class="lineno" href="#L147">147</a></span>
<span id="L148" class="lineno"><a class="lineno" href="#L148">148</a></span>
<span id="L149" class="lineno"><a class="lineno" href="#L149">149</a></span>
<span id="L150" class="lineno"><a class="lineno" href="#L150">150</a></span>
<span id="L151" class="lineno"><a class="lineno" href="#L151">151</a></span>
<span id="L152" class="lineno"><a class="lineno" href="#L152">152</a></span>
<span id="L153" class="lineno"><a class="lineno" href="#L153">153</a></span>
<span id="L154" class="lineno"><a class="lineno" href="#L154">154</a></span>
<span id="L155" class="lineno"><a class="lineno" href="#L155">155</a></span>
<span id="L156" class="lineno"><a class="lineno" href="#L156">156</a></span>
<span id="L157" class="lineno"><a class="lineno" href="#L157">157</a></span>
<span id="L158" class="lineno"><a class="lineno" href="#L158">158</a></span>
<span id="L159" class="lineno"><a class="lineno" href="#L159">159</a></span>
<span id="L160" class="lineno"><a class="lineno" href="#L160">160</a></span>
<span id="L161" class="lineno"><a class="lineno" href="#L161">161</a></span>
<span id="L162" class="lineno"><a class="lineno" href="#L162">162</a></span>
<span id="L163" class="lineno"><a class="lineno" href="#L163">163</a></span>
<span id="L164" class="lineno"><a class="lineno" href="#L164">164</a></span>
<span id="L165" class="lineno"><a class="lineno" href="#L165">165</a></span>
<span id="L166" class="lineno"><a class="lineno" href="#L166">166</a></span>
<span id="L167" class="lineno"><a class="lineno" href="#L167">167</a></span>
<span id="L168" class="lineno"><a class="lineno" href="#L168">168</a></span>
<span id="L169" class="lineno"><a class="lineno" href="#L169">169</a></span>
<span id="L170" class="lineno"><a class="lineno" href="#L170">170</a></span>
<span id="L171" class="lineno"><a class="lineno" href="#L171">171</a></span>
<span id="L172" class="lineno"><a class="lineno" href="#L172">172</a></span>
<span id="L173" class="lineno"><a class="lineno" href="#L173">173</a></span>
<span id="L174" class="lineno"><a class="lineno" href="#L174">174</a></span>
<span id="L175" class="lineno"><a class="lineno" href="#L175">175</a></span>
<span id="L176" class="lineno"><a class="lineno" href="#L176">176</a></span>
<span id="L177" class="lineno"><a class="lineno" href="#L177">177</a></span>
<span id="L178" class="lineno"><a class="lineno" href="#L178">178</a></span>
<span id="L179" class="lineno"><a class="lineno" href="#L179">179</a></span>
<span id="L180" class="lineno"><a class="lineno" href="#L180">180</a></span>
<span id="L181" class="lineno"><a class="lineno" href="#L181">181</a></span>
<span id="L182" class="lineno"><a class="lineno" href="#L182">182</a></span>
<span id="L183" class="lineno"><a class="lineno" href="#L183">183</a></span>
<span id="L184" class="lineno"><a class="lineno" href="#L184">184</a></span>
<span id="L185" class="lineno"><a class="lineno" href="#L185">185</a></span>
<span id="L186" class="lineno"><a class="lineno" href="#L186">186</a></span>
<span id="L187" class="lineno"><a class="lineno" href="#L187">187</a></span>
<span id="L188" class="lineno"><a class="lineno" href="#L188">188</a></span>
<span id="L189" class="lineno"><a class="lineno" href="#L189">189</a></span>
<span id="L190" class="lineno"><a class="lineno" href="#L190">190</a></span>
<span id="L191" class="lineno"><a class="lineno" href="#L191">191</a></span>
<span id="L192" class="lineno"><a class="lineno" href="#L192">192</a></span>
<span id="L193" class="lineno"><a class="lineno" href="#L193">193</a></span>
<span id="L194" class="lineno"><a class="lineno" href="#L194">194</a></span>
<span id="L195" class="lineno"><a class="lineno" href="#L195">195</a></span>
<span id="L196" class="lineno"><a class="lineno" href="#L196">196</a></span>
<span id="L197" class="lineno"><a class="lineno" href="#L197">197</a></span>
<span id="L198" class="lineno"><a class="lineno" href="#L198">198</a></span>
<span id="L199" class="lineno"><a class="lineno" href="#L199">199</a></span>
<span id="L200" class="lineno"><a class="lineno" href="#L200">200</a></span>
<span id="L201" class="lineno"><a class="lineno" href="#L201">201</a></span>
<span id="L202" class="lineno"><a class="lineno" href="#L202">202</a></span>
<span id="L203" class="lineno"><a class="lineno" href="#L203">203</a></span>
<span id="L204" class="lineno"><a class="lineno" href="#L204">204</a></span>
<span id="L205" class="lineno"><a class="lineno" href="#L205">205</a></span>
<span id="L206" class="lineno"><a class="lineno" href="#L206">206</a></span>
<span id="L207" class="lineno"><a class="lineno" href="#L207">207</a></span>
<span id="L208" class="lineno"><a class="lineno" href="#L208">208</a></span>
<span id="L209" class="lineno"><a class="lineno" href="#L209">209</a></span>
<span id="L210" class="lineno"><a class="lineno" href="#L210">210</a></span>
<span id="L211" class="lineno"><a class="lineno" href="#L211">211</a></span>
<span id="L212" class="lineno"><a class="lineno" href="#L212">212</a></span>
<span id="L213" class="lineno"><a class="lineno" href="#L213">213</a></span>
<span id="L214" class="lineno"><a class="lineno" href="#L214">214</a></span>
<span id="L215" class="lineno"><a class="lineno" href="#L215">215</a></span>
<span id="L216" class="lineno"><a class="lineno" href="#L216">216</a></span>
<span id="L217" class="lineno"><a class="lineno" href="#L217">217</a></span>
<span id="L218" class="lineno"><a class="lineno" href="#L218">218</a></span>
<span id="L219" class="lineno"><a class="lineno" href="#L219">219</a></span>
<span id="L220" class="lineno"><a class="lineno" href="#L220">220</a></span>
<span id="L221" class="lineno"><a class="lineno" href="#L221">221</a></span>
<span id="L222" class="lineno"><a class="lineno" href="#L222">222</a></span>
<span id="L223" class="lineno"><a class="lineno" href="#L223">223</a></span>
<span id="L224" class="lineno"><a class="lineno" href="#L224">224</a></span>
<span id="L225" class="lineno"><a class="lineno" href="#L225">225</a></span>
<span id="L226" class="lineno"><a class="lineno" href="#L226">226</a></span>
<span id="L227" class="lineno"><a class="lineno" href="#L227">227</a></span>
<span id="L228" class="lineno"><a class="lineno" href="#L228">228</a></span>
<span id="L229" class="lineno"><a class="lineno" href="#L229">229</a></span>
<span id="L230" class="lineno"><a class="lineno" href="#L230">230</a></span>
<span id="L231" class="lineno"><a class="lineno" href="#L231">231</a></span>
<span id="L232" class="lineno"><a class="lineno" href="#L232">232</a></span>
<span id="L233" class="lineno"><a class="lineno" href="#L233">233</a></span>
<span id="L234" class="lineno"><a class="lineno" href="#L234">234</a></span>
<span id="L235" class="lineno"><a class="lineno" href="#L235">235</a></span>
<span id="L236" class="lineno"><a class="lineno" href="#L236">236</a></span>
<span id="L237" class="lineno"><a class="lineno" href="#L237">237</a></span>
<span id="L238" class="lineno"><a class="lineno" href="#L238">238</a></span>
<span id="L239" class="lineno"><a class="lineno" href="#L239">239</a></span>
<span id="L240" class="lineno"><a class="lineno" href="#L240">240</a></span>
<span id="L241" class="lineno"><a class="lineno" href="#L241">241</a></span>
<span id="L242" class="lineno"><a class="lineno" href="#L242">242</a></span>
<span id="L243" class="lineno"><a class="lineno" href="#L243">243</a></span>
<span id="L244" class="lineno"><a class="lineno" href="#L244">244</a></span>
<span id="L245" class="lineno"><a class="lineno" href="#L245">245</a></span>
<span id="L246" class="lineno"><a class="lineno" href="#L246">246</a></span>
<span id="L247" class="lineno"><a class="lineno" href="#L247">247</a></span>
<span id="L248" class="lineno"><a class="lineno" href="#L248">248</a></span>
<span id="L249" class="lineno"><a class="lineno" href="#L249">249</a></span>
<span id="L250" class="lineno"><a class="lineno" href="#L250">250</a></span>
<span id="L251" class="lineno"><a class="lineno" href="#L251">251</a></span>
<span id="L252" class="lineno"><a class="lineno" href="#L252">252</a></span>
<span id="L253" class="lineno"><a class="lineno" href="#L253">253</a></span>
<span id="L254" class="lineno"><a class="lineno" href="#L254">254</a></span>
<span id="L255" class="lineno"><a class="lineno" href="#L255">255</a></span>
<span id="L256" class="lineno"><a class="lineno" href="#L256">256</a></span>
<span id="L257" class="lineno"><a class="lineno" href="#L257">257</a></span>
<span id="L258" class="lineno"><a class="lineno" href="#L258">258</a></span>
<span id="L259" class="lineno"><a class="lineno" href="#L259">259</a></span>
<span id="L260" class="lineno"><a class="lineno" href="#L260">260</a></span>
<span id="L261" class="lineno"><a class="lineno" href="#L261">261</a></span>
<span id="L262" class="lineno"><a class="lineno" href="#L262">262</a></span>
</pre></td>
<td class="table-code"><pre><span class="line-any" title="No Anys on this line!">import torch</span>
<span class="line-any" title="No Anys on this line!">import torch.nn.functional as F</span>
<span class="line-any" title="No Anys on this line!">import torch.nn as nn</span>
<span class="line-any" title="No Anys on this line!">from torch_geometric.utils import degree</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-precise" title="No Anys on this line!">from .models_misc import mlp</span>
<span class="line-any" title="No Anys on this line!">from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder</span>
<span class="line-any" title="No Anys on this line!">from ogb.utils.features import get_atom_feature_dims, get_bond_feature_dims </span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-any" title="No Anys on this line!">def multi_class_accuracy(y_hat, y, reduction='sum'):</span>
<span class="line-empty" title="No Anys on this line!">    </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x5)">    pred = y_hat.max(1)[1]</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">    if reduction == 'sum':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x9)">        acc = pred.eq(y).sum().float()</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">    elif reduction == 'mean':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x9)">        acc = pred.eq(y).mean().float()</span>
<span class="line-empty" title="No Anys on this line!">    else:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x4)">        raise NotImplementedError('Reduction {} not currently implemented.'.format(reduction))</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">    return acc</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-any" title="No Anys on this line!">def global_add_pool_sparse(x, batch):</span>
<span class="line-empty" title="No Anys on this line!">    </span>
<span class="line-empty" title="No Anys on this line!">    #-------------- global sum pooling</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x13)
Unimported (x2)">    index = torch.stack([batch, torch.tensor(list(range(batch.shape[0])), device=x.device)], 0)  </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x18)
Unimported (x3)">    x_sparse = torch.sparse.FloatTensor(index, x, torch.Size([torch.max(batch)+1, x.shape[0], x.shape[1]]))</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x6)
Unimported (x1)">    return torch.sparse.sum(x_sparse, 1).to_dense()</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-any" title="No Anys on this line!">def global_mean_pool_sparse(x, batch):</span>
<span class="line-empty" title="No Anys on this line!">    </span>
<span class="line-empty" title="No Anys on this line!">    #-------------- global average pooling</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x13)
Unimported (x2)">    index = torch.stack([batch, torch.tensor(list(range(batch.shape[0])), device=x.device)], 0)  </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x18)
Unimported (x3)">    x_sparse = torch.sparse.FloatTensor(index, x, torch.Size([torch.max(batch)+1, x.shape[0], x.shape[1]]))</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x5)
Unimported (x1)">    graph_sizes = degree(batch).float()</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x3)">    graph_sizes[graph_sizes==0.0] = 1.0</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x10)
Unimported (x1)">    return torch.sparse.sum(x_sparse, 1).to_dense() / graph_sizes.unsqueeze(1)</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-precise" title="No Anys on this line!">class DiscreteEmbedding(torch.nn.Module):</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-any" title="No Anys on this line!">    def __init__(self, encoder_name, d_in_features, d_in_encoder, d_out_encoder, **kwargs):</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">        super(DiscreteEmbedding, self).__init__()</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-empty" title="No Anys on this line!">        #-------------- various different embedding layers</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x4)">        kwargs['init'] = None if 'init' not in kwargs else kwargs['init']</span>
<span class="line-empty" title="No Anys on this line!">    </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        self.encoder_name = encoder_name</span>
<span class="line-empty" title="No Anys on this line!">        # d_in_features: input feature size (e.g. if already one hot encoded), </span>
<span class="line-empty" title="No Anys on this line!">        # d_in_encoder: number of unique values that will be encoded (size of embedding vocabulary)</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-empty" title="No Anys on this line!">        #-------------- fill embedding with zeros</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        if encoder_name == 'zero_encoder':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x4)">            self.encoder = zero_encoder(d_out_encoder)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">            d_out = d_out_encoder</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!">        #-------------- linear pojection</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        elif encoder_name == 'linear':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x5)
Unimported (x1)">            self.encoder = nn.Linear(d_in_features,  d_out_encoder, bias=True)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">            d_out = d_out_encoder</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!">        #-------------- mlp</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        elif encoder_name == 'mlp':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x9)">            self.encoder = mlp(d_in_features,</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">                               d_out_encoder,           </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">                               d_out_encoder,</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">                               kwargs['seed'],</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">                               kwargs['activation_mlp'],</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">                               kwargs['bn_mlp'])</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">            d_out = d_out_encoder</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!">        #-------------- multi hot encoding of categorical data</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        elif encoder_name == 'one_hot_encoder':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x4)">            self.encoder = one_hot_encoder(d_in_encoder)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x3)">            d_out = sum(d_in_encoder)</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!">        #-------------- embedding of categorical data (linear projection without bias of one hot encodings)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        elif encoder_name == 'embedding':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x12)">            self.encoder = multi_embedding(d_in_encoder, d_out_encoder, kwargs['aggr'], kwargs['init'])</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x3)">            if kwargs['aggr'] == 'concat':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x5)">                d_out = len(d_in_encoder) * d_out_encoder</span>
<span class="line-empty" title="No Anys on this line!">            else:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">                d_out = d_out_encoder</span>
<span class="line-empty" title="No Anys on this line!">                </span>
<span class="line-empty" title="No Anys on this line!">        #-------------- for ogb: multi hot encoding of node features</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        elif encoder_name == 'atom_one_hot_encoder':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x7)
Unimported (x2)">            full_atom_feature_dims = get_atom_feature_dims() if kwargs['features_scope'] == 'full' else get_atom_feature_dims()[:2]</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x4)">            self.encoder = one_hot_encoder(full_atom_feature_dims)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x3)">            d_out = sum(full_atom_feature_dims)</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-empty" title="No Anys on this line!">        #-------------- for ogb: multi hot encoding of edge features</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        elif encoder_name  == 'bond_one_hot_encoder':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x7)
Unimported (x2)">            full_bond_feature_dims = get_bond_feature_dims() if kwargs['features_scope'] == 'full' else  get_bond_feature_dims()[:2]</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x4)">            self.encoder  = one_hot_encoder(full_bond_feature_dims)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x3)">            d_out = sum(full_bond_feature_dims)</span>
<span class="line-empty" title="No Anys on this line!">                </span>
<span class="line-empty" title="No Anys on this line!">        #-------------- for ogb: embedding of node features</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        elif encoder_name == 'atom_encoder':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x3)
Unimported (x1)">            self.encoder  = AtomEncoder(d_out_encoder)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">            d_out = d_out_encoder</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!">        #-------------- for ogb: embedding of edge features</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        elif encoder_name  == 'bond_encoder':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x3)
Unimported (x1)">            self.encoder  = BondEncoder(emb_dim = d_out_encoder)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">            d_out = d_out_encoder</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!">        #-------------- no embedding, use as is</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        elif encoder_name == 'None':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">            self.encoder  = None</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">            d_out = d_in_features</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!">        else:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x4)">            raise NotImplementedError('Encoder {} is not currently supported.'.format(encoder_name))</span>
<span class="line-empty" title="No Anys on this line!">            </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        self.d_out = d_out</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-empty" title="No Anys on this line!">        return</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-any" title="No Anys on this line!">    def forward(self, x):</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x10)">        x = x.unsqueeze(-1) if x.dim() == 1 else x</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">        if self.encoder is not None:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x12)">            x = x.float() if self.encoder_name ==  'linear' or self.encoder_name == 'mlp' else x.long()</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x3)">            return self.encoder(x)</span>
<span class="line-empty" title="No Anys on this line!">        else:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x3)">            return x.float()    </span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-precise" title="No Anys on this line!">class multi_embedding(torch.nn.Module):</span>
<span class="line-empty" title="No Anys on this line!">    </span>
<span class="line-any" title="No Anys on this line!">    def __init__(self, d_in, d_out, aggr = 'concat', init=None):</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">        super(multi_embedding, self).__init__()</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-empty" title="No Anys on this line!">        #-------------- embedding of multiple categorical features. Summation or concatenation of the embeddings is allowed</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        self.d_in = d_in</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        self.aggr = aggr</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">        self.encoder = []</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x4)">        for i in range(len(d_in)):</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x9)
Unimported (x1)">            self.encoder.append(nn.Embedding(d_in[i], d_out))</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">            if init == 'zeros':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">                print('### INITIALIZING EMBEDDING TO ZERO ###')</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x9)
Unimported (x1)">                torch.nn.init.constant_(self.encoder[i].weight.data, 0)</span>
<span class="line-empty" title="No Anys on this line!">            else:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x9)
Unimported (x1)">                torch.nn.init.xavier_uniform_(self.encoder[-1].weight.data)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x4)
Unimported (x1)">        self.encoder = nn.ModuleList(self.encoder)   </span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-empty" title="No Anys on this line!">        return </span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-any" title="No Anys on this line!">    def forward(self, tensor):</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x5)">        for i in range(tensor.shape[1]):</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x8)">            embedding_i = self.encoder[i](tensor[:,i])</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">            if self.aggr == 'concat':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x7)
Unimported (x1)">                embedding = torch.cat((embedding, embedding_i),1) if i&gt;0 else embedding_i</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">            elif self.aggr == 'sum':</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x7)">                embedding = embedding + embedding_i if i&gt;0 else embedding_i</span>
<span class="line-empty" title="No Anys on this line!">            else:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x4)">                raise NotImplementedError('multi embedding aggregation {} is not currently supported.'.format(self.aggr))</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">        return embedding</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-precise" title="No Anys on this line!">class one_hot_encoder(torch.nn.Module):</span>
<span class="line-empty" title="No Anys on this line!">    </span>
<span class="line-any" title="No Anys on this line!">    def __init__(self, d_in):</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">        super(one_hot_encoder, self).__init__()</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        self.d_in = d_in</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-empty" title="No Anys on this line!">        return </span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-any" title="No Anys on this line!">    def forward(self, tensor):</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x5)">        for i in range(tensor.shape[1]):</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x11)
Unimported (x1)">            onehot_i = torch.zeros((tensor.shape[0], self.d_in[i]), device=tensor.device)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x8)">            onehot_i.scatter_(1, tensor[:,i:i+1], 1)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x7)
Unimported (x1)">            onehot = torch.cat((onehot, onehot_i), 1) if i&gt;0 else onehot_i</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">        return onehot</span>
<span class="line-empty" title="No Anys on this line!">    </span>
<span class="line-any" title="No Anys on this line!">    def __repr__(self):</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x5)">        return '{}({})'.format(self.__class__.__name__, self.d_in)</span>
<span class="line-empty" title="No Anys on this line!">    </span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-precise" title="No Anys on this line!">class zero_encoder(torch.nn.Module):</span>
<span class="line-empty" title="No Anys on this line!">    </span>
<span class="line-any" title="No Anys on this line!">    def __init__(self, d_out):</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">        super(zero_encoder, self).__init__()</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        self.d_out = d_out</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-empty" title="No Anys on this line!">        return </span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-any" title="No Anys on this line!">    def forward(self, tensor):</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x8)
Unimported (x1)">        return torch.zeros((tensor.shape[0], self.d_out), device=tensor.device)</span>
<span class="line-empty" title="No Anys on this line!">    </span>
<span class="line-any" title="No Anys on this line!">    def __repr__(self):</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x5)">        return '{}({})'.format(self.__class__.__name__, self.d_out) </span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-precise" title="No Anys on this line!">class central_encoder(nn.Module):</span>
<span class="line-empty" title="No Anys on this line!">    </span>
<span class="line-any" title="No Anys on this line!">    def __init__(self, nb_encoder, d_ef, extend=True):</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">        super(central_encoder, self).__init__()</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-empty" title="No Anys on this line!">        #-------------- For the neighbor aggregation: central node embedding</span>
<span class="line-empty" title="No Anys on this line!">        #-------------- This is a way to create a dummy variable that represents self loops.</span>
<span class="line-empty" title="No Anys on this line!">        #-------------- Useful when working with edge features or GSN-e</span>
<span class="line-empty" title="No Anys on this line!">        #-------------- Two ways are allowed: extra dummy variable (one hot or embedding) or a vector filled with zeros</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        self.extend = extend</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        self.nb_encoder = nb_encoder</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">        if self.extend:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">            print('##### EXTENDING EDGE FEATURE DIMENSIONS #####')</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">        if 'one_hot_encoder' in nb_encoder:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">            if self.extend:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x9)">                self.encoder = DiscreteEmbedding('one_hot_encoder', 1, [d_ef+1], None)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x3)">                self.d_out = d_ef+1</span>
<span class="line-empty" title="No Anys on this line!">            else:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">                self.d_out = d_ef</span>
<span class="line-empty" title="No Anys on this line!">        else:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">            self.d_out = d_ef</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">            if self.extend:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x8)">                self.encoder = DiscreteEmbedding('embedding',  None, [1], d_ef, aggr='sum')</span>
<span class="line-empty" title="No Anys on this line!">            else:</span>
<span class="line-any" title="No Anys on this line!">                pass</span>
<span class="line-empty" title="No Anys on this line!">            </span>
<span class="line-empty" title="No Anys on this line!">        return</span>
<span class="line-empty" title="No Anys on this line!"></span>
<span class="line-any" title="No Anys on this line!">    def forward(self, x_nb, num_nodes):</span>
<span class="line-empty" title="No Anys on this line!">        </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">        if 'one_hot_encoder' in self.nb_encoder:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">            if self.extend:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x8)
Unimported (x1)">                zero_extension = torch.zeros((x_nb.shape[0], 1), device=x_nb.device)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x6)
Unimported (x1)">                x_nb = torch.cat((zero_extension, x_nb), -1)</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x8)
Unimported (x1)">                x_central = torch.zeros((num_nodes,1), device=x_nb.device).long()</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x4)">                x_central = self.encoder(x_central)</span>
<span class="line-empty" title="No Anys on this line!">            else:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x7)
Unimported (x1)">                x_central = torch.zeros((num_nodes, self.d_out), device=x_nb.device)</span>
<span class="line-empty" title="No Anys on this line!">        else:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x1)">            if self.extend:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x8)
Unimported (x1)">                x_central = torch.zeros((num_nodes,1), device=x_nb.device).long()</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x4)">                x_central = self.encoder(x_central)</span>
<span class="line-empty" title="No Anys on this line!">            else:</span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x7)
Unimported (x1)">                x_central = torch.zeros((num_nodes, self.d_out), device=x_nb.device)</span>
<span class="line-empty" title="No Anys on this line!">            </span>
<span class="line-any" title="Any Types on this line: 
Unannotated (x2)">        return x_central, x_nb</span>
<span class="line-empty" title="No Anys on this line!">    </span>
<span class="line-empty" title="No Anys on this line!">    </span>
</pre></td>
</tr></tbody>
</table>
</body>
</html>
